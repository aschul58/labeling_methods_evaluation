{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8715e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from config.ipynb\n",
      "importing Jupyter notebook from data_preparation.ipynb\n",
      "importing Jupyter notebook from data_exploration.ipynb\n",
      "importing Jupyter notebook from labeling.ipynb\n",
      "importing Jupyter notebook from model_training.ipynb\n",
      "importing Jupyter notebook from label_exploration.ipynb\n",
      "importing Jupyter notebook from evaluate_ml_metrics.ipynb\n",
      "importing Jupyter notebook from evaluate_financial_metrics.ipynb\n",
      "importing Jupyter notebook from make_visualizations.ipynb\n",
      "importing Jupyter notebook from feature_engineering.ipynb\n",
      "importing Jupyter notebook from utilities.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statistics\n",
    "import import_ipynb\n",
    "from config import *\n",
    "from data_preparation import *\n",
    "from data_exploration import *\n",
    "from labeling import *\n",
    "from model_training import *\n",
    "from label_exploration import *\n",
    "from evaluate_ml_metrics import *\n",
    "from evaluate_financial_metrics import *\n",
    "from make_visualizations import *\n",
    "import pickle\n",
    "import numpy as np\n",
    "from feature_engineering import *\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94977bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the script. It controls the workflow of data preparation, labeling, visualization,\n",
    "    training, and evaluation based on the configuration flags.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Run time configuration\n",
    "    prepare_data = False\n",
    "    visualize_price_development = False\n",
    "    label_data = False\n",
    "    visualize_labels = False\n",
    "    feature_engineering = False\n",
    "    train_model = False\n",
    "    explore_label_distribution = False\n",
    "    evaluate_ml_metrics = False\n",
    "    evaluate_financial_metrics = False\n",
    "    print_latex = False\n",
    "    \n",
    "    ### Data Preparation ###\n",
    "    if prepare_data:\n",
    "        # Dictionary as data structure with coin name as key which stores the according dataframe \n",
    "        daily_crypto_dict = {}\n",
    "        weekly_crypto_dict = {}\n",
    "    \n",
    "        # Reading the CSV files of crypto currencies for daily and weekly directories\n",
    "        daily_dict = read_dir_of_csv(daily_crypto_dict, directory_daily)\n",
    "        weekly_dict = read_dir_of_csv(weekly_crypto_dict, directory_weekly)\n",
    "        \n",
    "        # Drop rows where no data for prices available (crypto currency is too young)\n",
    "        daily_dict = clean_dfs_prices(daily_dict)\n",
    "        weekly_dict = clean_dfs_prices(weekly_dict)\n",
    "        \n",
    "        #describe_dfs(daily_dict)\n",
    "        #print(\"-\" * 50)\n",
    "        #describe_dfs(weekly_dict)\n",
    "        \n",
    "        # Convert timestamps to datetime\n",
    "        daily_dict = convert_timestamps(daily_dict)\n",
    "        weekly_dict = convert_timestamps(weekly_dict)\n",
    "    \n",
    "        # Assign time horizon for each data point according to the window that was defined in the config\n",
    "        daily_dict = assign_horizons(daily_dict, delta)\n",
    "        weekly_dict = assign_horizons(weekly_dict, delta)\n",
    "        \n",
    "        # Align data tails according to the configured time window\n",
    "        daily_dict = allign_all_tails(daily_dict, window_in_days)\n",
    "        weekly_dict = allign_all_tails(weekly_dict, window_in_days)\n",
    "\n",
    "        print(calculate_outlier_profits(daily_dict, weekly_dict))\n",
    "        \n",
    "        if visualize_price_development:\n",
    "            visualize_price_development_for_timeframe(daily_dict[\"Ethereum\"], 30, \"visualizations/price_development_ethereum.png\")\n",
    "        \n",
    "        save_dictionary(\"dump_dictionaries/daily_dict.pkl\", daily_dict)\n",
    "        save_dictionary(\"dump_dictionaries/weekly_dict.pkl\", weekly_dict)\n",
    "    \n",
    "    if label_data:\n",
    "        if not prepare_data:\n",
    "            daily_dict = load_dictionary(\"dump_dictionaries/daily_dict.pkl\")\n",
    "            weekly_dict = load_dictionary(\"dump_dictionaries/weekly_dict.pkl\")\n",
    "        \n",
    "        # Label the currencies according to the triple barrier method\n",
    "        daily_dict = apply_tbm(daily_dict, volatility_delta)\n",
    "        weekly_dict = apply_tbm(weekly_dict, volatility_delta)\n",
    "        \n",
    "        # Label the currencies according to the fixed horizon method\n",
    "        daily_dict = apply_fixed_time_horizon(daily_dict, threshold)\n",
    "        weekly_dict = apply_fixed_time_horizon(weekly_dict, threshold)\n",
    "        \n",
    "        # Assign relative returns within the given horizon\n",
    "        daily_dict = assign_relative_returns(daily_dict)\n",
    "        weekly_dict = assign_relative_returns(weekly_dict)\n",
    "\n",
    "        # Calculate and store the market means and median on a daily and weekly basis\n",
    "        daily_mean_returns, daily_median_returns = calculate_mean_median_market_return(daily_dict)\n",
    "        weekly_mean_returns, weekly_median_returns = calculate_mean_median_market_return(weekly_dict)\n",
    "        \n",
    "        # Apply excess over mean and median labeling\n",
    "        daily_dict = assign_excess_over_mean_median_label(daily_dict, daily_mean_returns, daily_median_returns)\n",
    "        weekly_dict = assign_excess_over_mean_median_label(weekly_dict, weekly_mean_returns, weekly_median_returns)\n",
    "        \n",
    "        # Assign tail sets\n",
    "        daily_dict = assign_tail_sets(daily_dict)\n",
    "        weekly_dict = assign_tail_sets(weekly_dict)\n",
    "        \n",
    "        # Assign trend scanning\n",
    "        daily_dict = assign_trend_scanning(daily_dict)\n",
    "        weekly_dict = assign_trend_scanning(weekly_dict)\n",
    "        \n",
    "        # Assign matrix flag labeling\n",
    "        daily_dict = assign_matrix_flags(daily_dict)\n",
    "        weekly_dict = assign_matrix_flags(weekly_dict)\n",
    "        \n",
    "        # Assign next day labeling\n",
    "        daily_dict = apply_next_period_return_labeling(daily_dict)\n",
    "        weekly_dict = apply_next_period_return_labeling(weekly_dict)\n",
    "        \n",
    "        save_dictionary(\"dump_dictionaries/daily_dict.pkl\", daily_dict)\n",
    "        save_dictionary(\"dump_dictionaries/weekly_dict.pkl\", weekly_dict)\n",
    "    \n",
    "    if explore_label_distribution:\n",
    "        if not label_data:\n",
    "            daily_dict = load_dictionary(\"dump_dictionaries/daily_dict.pkl\")\n",
    "            weekly_dict = load_dictionary(\"dump_dictionaries/weekly_dict.pkl\")\n",
    "        \n",
    "        # Explore how labels are distributed\n",
    "        label_distribution_daily = check_label_distribution(daily_dict)\n",
    "        label_distribution_weekly = check_label_distribution(weekly_dict)\n",
    "        label_distribution_daily.to_excel(\"raw_results/label_distribution_daily.xlsx\")\n",
    "        label_distribution_weekly.to_excel(\"raw_results/label_distribution_weekly.xlsx\")\n",
    "        plot_label_distribution(label_distribution_daily, \"visualizations/label_distribution_daily\")\n",
    "        plot_label_distribution(label_distribution_weekly, \"visualizations/label_distribution_weekly\")\n",
    "        \n",
    "        explore_and_visualize_overlap(daily_dict, label_columns, \"visualizations/label_overlap\", \"daily\")\n",
    "        explore_and_visualize_overlap(weekly_dict, label_columns, \"visualizations/label_overlap\", \"weekly\")\n",
    "        \n",
    "        # Merge all currencies into one dataframe so that the model can be trained on the crypto market instead of particular currencies\n",
    "        explore_crypto_market_daily = merge_currencies(daily_dict)\n",
    "        explore_crypto_market_weekly = merge_currencies(weekly_dict)\n",
    "        \n",
    "        daily_overlaps_df = explore_label_overlap(explore_crypto_market_daily, label_columns)\n",
    "        weekly_overlaps_df = explore_label_overlap(explore_crypto_market_weekly, label_columns)\n",
    "        \n",
    "        visualize_label_overlap(daily_overlaps_df, \"market\", \"visualizations/label_overlap\", \"daily\")\n",
    "        visualize_label_overlap(weekly_overlaps_df, \"market\", \"visualizations/label_overlap\", \"weekly\")\n",
    "    \n",
    "    if visualize_labels:\n",
    "        if not label_data:\n",
    "            daily_dict = load_dictionary(\"dump_dictionaries/daily_dict.pkl\")\n",
    "            weekly_dict = load_dictionary(\"dump_dictionaries/weekly_dict.pkl\")\n",
    "        \n",
    "        plot_trend_labels(daily_dict[\"Ethereum\"], label_columns)\n",
    "    \n",
    "    if train_model:\n",
    "        if not label_data:\n",
    "            daily_dict = load_dictionary(\"dump_dictionaries/daily_dict.pkl\")\n",
    "            weekly_dict = load_dictionary(\"dump_dictionaries/weekly_dict.pkl\")\n",
    "            \n",
    "        # Feature engineering\n",
    "        if feature_engineering:\n",
    "            from config import train_feature_list\n",
    "            daily_dict = add_features(daily_dict)\n",
    "            weekly_dict = add_features(weekly_dict)\n",
    "            train_feature_list += engineering_features\n",
    "        \n",
    "        # Merge all currencies into one dataframe so that the model can be trained on the crypto market instead of particular currencies\n",
    "        crypto_market_daily = merge_currencies(daily_dict)\n",
    "        crypto_market_weekly = merge_currencies(weekly_dict)\n",
    "        \n",
    "        # Train lgbm classifier based on the previously assigned labels\n",
    "        trained_currencies_daily = apply_training(crypto_market_daily)\n",
    "        trained_currencies_weekly = apply_training(crypto_market_weekly)\n",
    "        \n",
    "        # Separate the training results based on currencies\n",
    "        currencies_results_daily = split_training_results_in_currencies(trained_currencies_daily)\n",
    "        currencies_results_weekly = split_training_results_in_currencies(trained_currencies_weekly)\n",
    "        \n",
    "        save_dictionary(\"dump_dictionaries/trained_currencies_daily.pkl\", trained_currencies_daily)\n",
    "        save_dictionary(\"dump_dictionaries/trained_currencies_weekly.pkl\", trained_currencies_weekly)\n",
    "        save_dictionary(\"dump_dictionaries/currencies_results_daily.pkl\", currencies_results_daily)\n",
    "        save_dictionary(\"dump_dictionaries/currencies_results_weekly.pkl\", currencies_results_weekly)\n",
    "    \n",
    "    if evaluate_ml_metrics:\n",
    "        if not train_model:\n",
    "            trained_currencies_daily = load_dictionary(\"dump_dictionaries/trained_currencies_daily.pkl\")\n",
    "            trained_currencies_weekly = load_dictionary(\"dump_dictionaries/trained_currencies_weekly.pkl\")\n",
    "            currencies_results_daily = load_dictionary(\"dump_dictionaries/currencies_results_daily.pkl\")\n",
    "            currencies_results_weekly = load_dictionary(\"dump_dictionaries/currencies_results_weekly.pkl\")\n",
    "        \n",
    "        \n",
    "        # Evaluate overall model accuracies (across all currencies)\n",
    "        train_test_accuracy_daily = evaluate_overall_accuracy(trained_currencies_daily)\n",
    "        train_test_accuracy_weekly = evaluate_overall_accuracy(trained_currencies_weekly)\n",
    "        train_test_accuracy_daily.to_excel(\"raw_results/train_test_accuracy_daily.xlsx\", index=False)\n",
    "        train_test_accuracy_weekly.to_excel(\"raw_results/train_test_accuracy_weekly.xlsx\", index=False)\n",
    "        \n",
    "        # Evaluate accuracy for each currency separately\n",
    "        #print_latex_table(evaluate_currency_accuracy(currencies_results_daily))\n",
    "        #print_latex_table(evaluate_currency_accuracy(currencies_results_weekly))\n",
    "        \n",
    "        key_ml_metrics_daily = evaluate_labeling_techniques(trained_currencies_daily)\n",
    "        key_ml_metrics_weekly = evaluate_labeling_techniques(trained_currencies_weekly)\n",
    "        key_ml_metrics_daily.to_excel(\"raw_results/key_ml_metrics_daily.xlsx\", index=False)\n",
    "        key_ml_metrics_weekly.to_excel(\"raw_results/key_ml_metrics_weekly.xlsx\", index=False)\n",
    "        #print_latex_table_small(key_ml_metrics_daily)\n",
    "        \n",
    "        metrics_per_class_daily = evaluate_and_visualize_all_approaches(trained_currencies_daily)\n",
    "        metrics_per_class_weekly = evaluate_and_visualize_all_approaches(trained_currencies_weekly)\n",
    "        metrics_per_class_daily.to_excel(\"raw_results/ metrics_per_class_daily.xlsx\", index=False)\n",
    "        metrics_per_class_weekly.to_excel(\"raw_results/ metrics_per_class_weekly.xlsx\", index=False)\n",
    "        #print_latex_table_small(metrics_per_class_daily)\n",
    "    \n",
    "    if evaluate_financial_metrics:\n",
    "        if not train_model:\n",
    "            trained_currencies_daily = load_dictionary(\"dump_dictionaries/trained_currencies_daily.pkl\")\n",
    "            trained_currencies_weekly = load_dictionary(\"dump_dictionaries/trained_currencies_weekly.pkl\")\n",
    "            currencies_results_daily = load_dictionary(\"dump_dictionaries/currencies_results_daily.pkl\")\n",
    "            currencies_results_weekly = load_dictionary(\"dump_dictionaries/currencies_results_weekly.pkl\")\n",
    "            \n",
    "        #market_returns_daily = calculate_market_returns(trained_currencies_daily)\n",
    "        #market_returns_weekly = calculate_market_returns(trained_currencies_weekly)\n",
    "        \n",
    "        #visualize_overall_returns(market_returns_daily, 'visualizations/market_returns_daily.png')\n",
    "        #visualize_overall_returns(market_returns_weekly, 'visualizations/market_returns_weekly.png')\n",
    "        \n",
    "        periods = evaluate_different_holding_periods(currencies_results_daily)\n",
    "        periods.to_excel(\"raw_results/periods.xlsx\", index=False)\n",
    "        \n",
    "        currencies_results_daily, evaluation_df_daily, market_results_daily = evaluate_strategy_financially(currencies_results_daily, periods=\"daily\")\n",
    "        currencies_results_weekly, evaluation_df_weekly,market_results_weekly = evaluate_strategy_financially(currencies_results_weekly, periods=\"weekly\")\n",
    "        \n",
    "        evaluation_df_daily.to_excel(\"raw_results/currencies_daily.xlsx\", index=False)\n",
    "        evaluation_df_weekly.to_excel(\"raw_results/currencies_weekly.xlsx\", index=False)\n",
    "        market_results_daily.to_excel(\"raw_results/market_daily.xlsx\", index=False)\n",
    "        market_results_weekly.to_excel(\"raw_results/market_weekly.xlsx\", index=False)\n",
    "        \n",
    "        \n",
    "        visualize_overall_returns(market_results_daily, 'visualizations/market_returns_daily.png')\n",
    "        visualize_overall_returns(market_results_weekly, 'visualizations/market_returns_weekly.png')\n",
    "        visualize_overall_returns_vertical(market_results_daily, market_results_weekly, 'visualizations/market_returns_comparison.png')\n",
    "        \n",
    "        visualize_risk_metrics_radar_plot(market_results_daily, 'visualizations/risk_radar_daily.png')\n",
    "        visualize_risk_metrics_radar_plot(market_results_weekly, 'visualizations/risk_radar_weekly.png')\n",
    "        \n",
    "        plot_distribution_combined(currencies_results_daily, 'visualizations/return_distribution_daily.png', 0.006)\n",
    "        plot_distribution_combined(currencies_results_weekly, 'visualizations/return_distribution_weekly.png', 0.006)\n",
    "        \n",
    "        trading_metrics_daily = evaluate_trades_overview(currencies_results_daily, 0.006)\n",
    "        trading_metrics_weekly = evaluate_trades_overview(currencies_results_weekly, 0.006)\n",
    "        trading_metrics_daily.to_excel(\"raw_results/trading_metrics_daily.xlsx\", index=False)\n",
    "        trading_metrics_weekly.to_excel(\"raw_results/trading_metrics_weekly.xlsx\", index=False)\n",
    "\n",
    "    if print_latex:\n",
    "        # Label distribution \n",
    "        print(\"Label distribution daily\")\n",
    "        basic_latex_table(label_distribution_daily)\n",
    "        print(\"-\"*100)\n",
    "        print(\"Label distribution weekly\")\n",
    "        basic_latex_table(label_distribution_weekly)\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        # Ml metrics\n",
    "        print(\"Key ML metrics\")\n",
    "        print_key_ml_to_latex(key_ml_metrics_daily, key_ml_metrics_weekly)\n",
    "        print(\"-\"*100)\n",
    "        print(\"Metrics per class daily\")\n",
    "        print_classification_report_to_latex(metrics_per_class_daily)\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        # Financial metrics\n",
    "        print(\"Overall market daily\")\n",
    "        print_financial_overview_to_latex(market_results_daily)\n",
    "        print(\"-\"*100)\n",
    "        print(\"Overall market weekly\")\n",
    "        print_financial_overview_to_latex(market_results_weekly)\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        # Trade metrics\n",
    "        print(\"Trade metrics\")\n",
    "        print_trade_metrics_to_latex(trading_metrics_daily, trading_metrics_weekly)\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        #holding periods\n",
    "        print(\"Holding periods\")\n",
    "        print_holding_periods_to_latex(periods)\n",
    "        print(\"-\"*100)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc1ee2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrr}\n",
      "\\toprule\n",
      "Dataset & Currency & Maximum return & Ratio outliers & Number \\\\\n",
      "\\midrule\n",
      "daily & Chainlink & 10904.224638 & 0.565899 & 1 \\\\\n",
      "daily & Curve & 6819.571994 & 1.544180 & 2 \\\\\n",
      "daily & Ribbon & 3494.980942 & 3.449933 & 2 \\\\\n",
      "daily & Uniswap & 5160.906512 & 1.959536 & 1 \\\\\n",
      "daily & Dydx & 3982.986133 & 0.000000 & 0 \\\\\n",
      "daily & Aave & 19360.705588 & 39.160540 & 5 \\\\\n",
      "daily & Lido & 6744.442980 & 2.791410 & 3 \\\\\n",
      "daily & Polygon & 8472.409607 & 4.061551 & 6 \\\\\n",
      "daily & Ethereum & 9032.506701 & 0.000000 & 0 \\\\\n",
      "daily & Bitcoin & 6697.803771 & 0.000000 & 0 \\\\\n",
      "daily & SHIB & 5692.750422 & 25.776327 & 12 \\\\\n",
      "daily & Pepe & 1906.388714 & 28.228434 & 6 \\\\\n",
      "weekly & Chainlink & 4415.763053 & 14.137024 & 9 \\\\\n",
      "weekly & Curve & 2441.246690 & 14.479397 & 5 \\\\\n",
      "weekly & Ribbon & 1560.872268 & 19.578688 & 5 \\\\\n",
      "weekly & Uniswap & 1775.650117 & 9.620316 & 3 \\\\\n",
      "weekly & Dydx & 1542.777563 & 25.153485 & 6 \\\\\n",
      "weekly & Aave & 11472.280371 & 65.394976 & 11 \\\\\n",
      "weekly & Lido & 2537.034894 & 29.279960 & 10 \\\\\n",
      "weekly & Polygon & 3517.659768 & 25.007552 & 8 \\\\\n",
      "weekly & Ethereum & 3926.543962 & 10.131141 & 5 \\\\\n",
      "weekly & Bitcoin & 2832.854932 & 0.000000 & 0 \\\\\n",
      "weekly & SHIB & 3420.641358 & 67.576130 & 6 \\\\\n",
      "weekly & Pepe & 941.829093 & 65.836507 & 4 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "   Dataset   Currency  Maximum return  Ratio outliers  Number\n",
      "0    daily  Chainlink    10904.224638        0.565899       1\n",
      "1    daily      Curve     6819.571994        1.544180       2\n",
      "2    daily     Ribbon     3494.980942        3.449933       2\n",
      "3    daily    Uniswap     5160.906512        1.959536       1\n",
      "4    daily       Dydx     3982.986133        0.000000       0\n",
      "5    daily       Aave    19360.705588       39.160540       5\n",
      "6    daily       Lido     6744.442980        2.791410       3\n",
      "7    daily    Polygon     8472.409607        4.061551       6\n",
      "8    daily   Ethereum     9032.506701        0.000000       0\n",
      "9    daily    Bitcoin     6697.803771        0.000000       0\n",
      "10   daily       SHIB     5692.750422       25.776327      12\n",
      "11   daily       Pepe     1906.388714       28.228434       6\n",
      "12  weekly  Chainlink     4415.763053       14.137024       9\n",
      "13  weekly      Curve     2441.246690       14.479397       5\n",
      "14  weekly     Ribbon     1560.872268       19.578688       5\n",
      "15  weekly    Uniswap     1775.650117        9.620316       3\n",
      "16  weekly       Dydx     1542.777563       25.153485       6\n",
      "17  weekly       Aave    11472.280371       65.394976      11\n",
      "18  weekly       Lido     2537.034894       29.279960      10\n",
      "19  weekly    Polygon     3517.659768       25.007552       8\n",
      "20  weekly   Ethereum     3926.543962       10.131141       5\n",
      "21  weekly    Bitcoin     2832.854932        0.000000       0\n",
      "22  weekly       SHIB     3420.641358       67.576130       6\n",
      "23  weekly       Pepe      941.829093       65.836507       4\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'excess_over_mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/newenv/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/newenv/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/newenv/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'excess_over_mean'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 107\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m     weekly_dict \u001b[38;5;241m=\u001b[39m load_dictionary(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdump_dictionaries/weekly_dict.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Explore how labels are distributed\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m label_distribution_daily \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_label_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdaily_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m label_distribution_weekly \u001b[38;5;241m=\u001b[39m check_label_distribution(weekly_dict)\n\u001b[1;32m    109\u001b[0m label_distribution_daily\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_results/label_distribution_daily.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m<string>:31\u001b[0m, in \u001b[0;36mcheck_label_distribution\u001b[0;34m(dictionary)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/newenv/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/newenv/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'excess_over_mean'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9733ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
